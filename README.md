
# Hospital Readmission Pipeline (ML + Airflow)

This project implements a complete machine learning pipeline for predicting hospital readmissions. It uses Apache Airflow to orchestrate tasks, MLflow to track model training, Docker for environment isolation, and DVC for data versioning.

---

## Project Summary

- **ML Tasks**: Data ingestion, cleaning, feature engineering, training, evaluation.
- **Orchestration**: Airflow DAG uses `BashOperator` to run each step in the ML pipeline.
- **Tracking**: MLflow logs metrics, parameters, and artifacts.
- **Versioning**: DVC tracks raw and processed datasets.
- **Environment Isolation**: Two Docker containers (`airflow`, `ml-pipeline`).
- **Service Management**: Docker Compose launches the full stack.

---

## Repository Layout

```
readmission-pipeline-ml/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ readmission_dag.py         # DAG defining ML pipeline orchestration
â”‚   â”œâ”€â”€ Dockerfile                     # Airflow service container
â”‚   â”œâ”€â”€ init.sh                        # DB init & graceful handling script
â”‚   â””â”€â”€ requirements.txt               # Python dependencies for Airflow
â”‚
â”œâ”€â”€ ml-pipeline/
â”‚   â”œâ”€â”€ Dockerfile                     # ML pipeline container
â”‚   â””â”€â”€ requirements.txt               # Python dependencies for ML tasks
â”‚
â”œâ”€â”€ scripts/                           # Modular ML pipeline components
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ clean.py
â”‚   â”œâ”€â”€ drop_column.py
â”‚   â”œâ”€â”€ feature_engineering.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â””â”€â”€ pipeline.py                    # (Optional) End-to-end runner
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ hospital_readmissions.csv  # Raw source data
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ cleaned_data.csv
â”‚       â”œâ”€â”€ featured_data.csv
â”‚       â”œâ”€â”€ test_data.pkl
â”‚       â””â”€â”€ *.dvc                      # DVC tracking files
â”‚
â”œâ”€â”€ mlruns/                            # MLflow experiment logs & model registry
â”‚   â”œâ”€â”€ 0/, ...                        # Individual run folders
â”‚   â””â”€â”€ models/ReadmissionModel/...   # Model versions and metadata
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb                   # Exploratory Data Analysis
â”‚   â””â”€â”€ 02_cleaning.ipynb              # Cleaning prototyping
â”‚
â”œâ”€â”€ models/                            # (Optional) Local model storage
â”œâ”€â”€ docker-compose.yml                 # Defines all services
â”œâ”€â”€ Makefile                           # Manual build/run commands (optional)
â”œâ”€â”€ env.yml                            # Old Conda environment spec
â”œâ”€â”€ last_run_id.txt                    # Stores last MLflow run ID
â”œâ”€â”€ confusion_matrix.png               # Evaluation artifact
â”œâ”€â”€ roc_curve.png                      # Evaluation artifact
â””â”€â”€ README.md                          # You are here!
```

---

## ğŸ§  ML Pipeline Steps

Each ML step is executed in a Dockerized script:

1. **Ingest** â†’ `scripts/ingest.py`
2. **Clean** â†’ `scripts/clean.py`
3. **Feature Engineering** â†’ `scripts/feature_engineering.py`
4. **Train Model** â†’ `scripts/train_model.py`
5. **Evaluate** â†’ `scripts/evaluate_model.py`

Artifacts and metrics are logged to MLflow.

---

## âš™ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             ğŸ§  User (You)                                   â”‚
â”‚   Runs: `docker compose up --build` to launch the full ML system stack     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Docker Compose Stack â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚     Airflow Container      â”‚          â”‚      ML Pipeline Container   â”‚    â”‚
â”‚  â”‚  - Airflow Webserver (UI)  â”‚â—„â”€â”€â”      â”‚  - Python 3.10, scikit-learn â”‚    â”‚
â”‚  â”‚  - Airflow Scheduler       â”‚   â”‚      â”‚  - Runs ML scripts           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                   â”‚                     â”‚                    â”‚
â”‚               â–¼                   â”‚                     â–¼                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ DAG: readmission_dag  â”‚â”€â”€â”€â”€â”€â”˜       â”‚   Scripts: clean, feature,   â”‚   â”‚
â”‚     â”‚ BashOperators (steps) â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   train, evaluate (Python)   â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚               â”‚                                                    â–²         â”‚
â”‚               â–¼                                                    â”‚         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚
â”‚   â”‚    PostgreSQL Container    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   Airflow Metadata â”‚  â”‚         â”‚
â”‚   â”‚ - Stores DAG/task state    â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚         â”‚
â”‚                                                                    â”‚         â”‚
â”‚                   Logs metrics and artifacts using                 â”‚         â”‚
â”‚                   MLflow Tracking Server (inside container)  â—„â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                         - model.pkl                                â”‚         â”‚
â”‚                         - metrics.json                             â”‚         â”‚
â”‚                         - confusion_matrix.png                     â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â–¼                                                                  â–²
        â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ§¬ Data Version Control (DVC) & Local Files             â”‚
â”‚                                                                            â”‚
â”‚  - Data files like cleaned_data.csv and test_data.pkl are DVC-tracked      â”‚
â”‚  - Stored **outside** Git to avoid large file issues                       â”‚
â”‚  - Only metadata `.dvc` files are committed to Git                         â”‚
â”‚  - Actual data lives in your local filesystem or DVC remote                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```


---

## ğŸ§ª Local Development

```bash
# Stop & reset containers
docker compose down -v

# Rebuild everything
docker compose build

# Launch stack
docker compose up
```

---

## Next Steps

- Trigger DAG and run full pipeline from Airflow UI
- View metrics & artifacts in MLflow UI
- Add FASTAPI or Streamlit frontend
- (Future) Deploy to the cloud
