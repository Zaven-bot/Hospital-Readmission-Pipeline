services:
  postgres:
    image: postgres:14
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
  # Provides the UI (localhost:8080) to view DAGs, trigger runs, monitor tasks
  airflow-webserver:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor # coordinate tasks between webserver and sched.
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # access to metadata
      AIRFLOW__WEBSERVER__RBAC: 'True'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'

      ## Airflow UI/API hung / failed to boot within the alloted 2 minutes
      AIRFLOW__WEBSERVER__WORKERS: 1
      AIRFLOW__WEBSERVER__WEB_SERVER_WORKER_TIMEOUT: 300
    ports:
      - "8080:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts # needs scripts to know where to command ml-pipeline
    # override ENTRYPOINT in Dockerfile
    entrypoint: ["/opt/airflow/init.sh", "webserver"]

  # Executes DAG tasks by watching the shedule or manual triggers
  airflow-scheduler:
    build:
      context: ./airflow
      dockerfile: Dockerfile
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor # coordinate tasks between webserver and sched.
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow  # access to metadata
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'

    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts # needs scripts to know where to command ml-pipeline
    entrypoint: ["/opt/airflow/init.sh", "scheduler"]

  ml-pipeline:
    build:
      context: ./ml-pipeline
      dockerfile: Dockerfile
    volumes:
      - ./scripts:/app/scripts
      - ./data:/app/data
      - ./models:/app/models
      - ./plots:/app/plots

# initialize named volume for use
volumes:
  postgres_data:
