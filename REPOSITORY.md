# ğŸ§­ Project Repository Overview

This document summarizes the structure and responsibilities of the `readmission-pipeline-ml/` repository.

---

## ğŸ“ Repository Structure

```
readmission-pipeline-ml/
â”œâ”€â”€ airflow/                      # Airflow container files and DAGs
â”‚   â”œâ”€â”€ dags/
â”‚   â”‚   â””â”€â”€ readmission_dag.py    # Airflow DAG orchestrating ML pipeline
â”‚   â”œâ”€â”€ Dockerfile                # Airflow Docker build
â”‚   â”œâ”€â”€ init.sh                   # Script to initialize Airflow DB and services
â”‚   â””â”€â”€ requirements.txt          # Airflow Python dependencies
â”‚
â”œâ”€â”€ ml-pipeline/                 # ML container files
â”‚   â”œâ”€â”€ Dockerfile                # ML pipeline Docker build
â”‚   â””â”€â”€ requirements.txt          # ML pipeline Python dependencies
â”‚
â”œâ”€â”€ scripts/                     # Source ML pipeline scripts
â”‚   â”œâ”€â”€ clean.py                  # Clean raw data
â”‚   â”œâ”€â”€ feature_engineering.py   # Feature transformation logic
â”‚   â”œâ”€â”€ train_model.py           # Train a model and log to MLflow
â”‚   â”œâ”€â”€ evaluate_model.py        # Evaluate model and log metrics
â”‚   â”œâ”€â”€ ingest.py                # Data ingestion logic
â”‚   â”œâ”€â”€ drop_column.py           # Utility script for feature dropping
â”‚   â””â”€â”€ pipeline.py              # Optional: complete pipeline runner
â”‚
â”œâ”€â”€ data/                        # Datasets
â”‚   â”œâ”€â”€ raw/                      # Raw input data
â”‚   â””â”€â”€ processed/                # Cleaned and feature-engineered data
â”‚       â””â”€â”€ *.dvc                 # DVC tracking files
â”‚
â”œâ”€â”€ mlruns/                      # MLflow tracking directory
â”‚   â””â”€â”€ ...                       # Logs, metrics, artifacts, models
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ 01_eda.ipynb             # Exploratory Data Analysis
â”‚   â””â”€â”€ 02_cleaning.ipynb        # Cleaning prototyping
â”‚
â”œâ”€â”€ models/                      # Optional: local saved models
â”‚
â”œâ”€â”€ .dvc/                        # DVC internal state
â”œâ”€â”€ .git/                        # Git version control
â”œâ”€â”€ docker-compose.yml           # Compose file to run containers
â”œâ”€â”€ Makefile                     # Utility commands (legacy/manual)
â”œâ”€â”€ env.yml                      # Old Conda environment (may be deprecated)
â”œâ”€â”€ requirements-af.txt          # Airflow environment dependencies
â”œâ”€â”€ requirements-ml.txt          # ML environment dependencies
â”œâ”€â”€ confusion_matrix.png         # Evaluation output
â”œâ”€â”€ roc_curve.png                # Evaluation output
â”œâ”€â”€ last_run_id.txt              # Possibly stores MLflow run ID
â”œâ”€â”€ README.md                    # Project README
â””â”€â”€ repository_layout.txt        # Notes on layout
```

---

## ğŸ” Component Responsibilities

### ğŸ§  ML Scripts (`scripts/`)

* **clean.py**: Cleans raw hospital data.
* **feature\_engineering.py**: Builds features used by model.
* **train\_model.py**: Trains a model, logs it to MLflow.
* **evaluate\_model.py**: Evaluates model and logs confusion matrix and scores.

### âš™ï¸ Workflow Automation

* **readmission\_dag.py**: Defines Airflow DAG with BashOperator to trigger each ML stage in its Docker container.
* **init.sh**: Handles `airflow db init` and service start logic with retries.
* **docker-compose.yml**: Spins up PostgreSQL, Airflow, and ML pipeline containers.

### ğŸ“¦ Versioning & Tracking

* **MLflow (`mlruns/`)**: Logs metrics, models, and run metadata.
* **DVC (`data/processed/*.dvc`)**: Tracks data versions.

### ğŸ“Š Notebooks

* Used to develop, clean, and explore data prior to scripting pipeline logic.

---

Let me know if you'd like to split this into separate markdown files or automatically update your `README.md` with summarized content!
